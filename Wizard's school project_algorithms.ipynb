{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7616d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#dataset division\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Classification Reports\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Stratified Kfolds\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Ensemble\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "#importing the GaussianNB classification algorithm\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "\n",
    "#MLP CLassifier, neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Best decision tree calculator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dff0e3",
   "metadata": {},
   "source": [
    "Info:\n",
    "The confusion matrix in sklearn is presented in the following format: <br>\n",
    "[ [ TN  FP  ] <br>\n",
    "    [ FN  TP ] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c11db4",
   "metadata": {},
   "source": [
    "# Metrics Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85874938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_train, pred_train , y_test, pred_test):\n",
    "    '''Takes, as arguments, the labels and predictions for both the training and the test data\n",
    "    Returns the classification_report and confusion matrix for training and test data'''\n",
    "    print('_____________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('_____________________________________')\n",
    "    print('                                                     TEST                                                  ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    print(confusion_matrix(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4809f70e",
   "metadata": {},
   "source": [
    "This function will be used to check the values of the metrics for the models that we will try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6776380b",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd06ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Data_after_feature_selection/train_data_scalled.csv\", index_col = 0)\n",
    "val = pd.read_csv(\"Data_after_feature_selection/val_data_scalled.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7801fa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Admitted in School\n",
       "0.0    323\n",
       "1.0    176\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Admitted in School\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4ca082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472945891783567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "323/(323+176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea792c31",
   "metadata": {},
   "source": [
    "As the number of 0 is 65% and the number of 1 is 35% we conclude that the dataset is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9330eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = \"Admitted in School\")\n",
    "y_train = train[[\"Admitted in School\"]]\n",
    "X_val = val.drop(columns = \"Admitted in School\")\n",
    "y_val = val[[\"Admitted in School\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a7e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_val], axis = 0)\n",
    "y = pd.concat([y_train, y_val], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f654e0",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f323624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_logistic_regression_params(X_train, y_train):\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2', \"elasticnet\"],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'saga'], \n",
    "        \"l1_ratio\" : [0.1, 0.3, 0.5, 0.7]\n",
    "    }\n",
    "\n",
    "    # Create a Logistic Regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    \n",
    "    #Creates RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(log_reg, param_grid, cv=rskf, scoring='f1')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca95de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_best_logistic_regression_params(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba74d2",
   "metadata": {},
   "source": [
    "Best Parameters: {'C': 4, 'penalty': 'l2', 'solver': 'liblinear', 'l1_ratio' = 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b081f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C = 4, penalty = 'l2', solver = 'liblinear', l1_ratio = 0.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ea4e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7726295467509104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, logreg.predict(X_val), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed2f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.89      0.87       323\n",
      "         1.0       0.78      0.72      0.75       176\n",
      "\n",
      "    accuracy                           0.83       499\n",
      "   macro avg       0.82      0.81      0.81       499\n",
      "weighted avg       0.83      0.83      0.83       499\n",
      "\n",
      "[[288  35]\n",
      " [ 49 127]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.83       138\n",
      "         1.0       0.71      0.63      0.67        76\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.74      0.75       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n",
      "[[118  20]\n",
      " [ 28  48]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = logreg.predict(X_train) , y_test = y_val, pred_test = logreg.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966ab11",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5b4b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numberK_list=np.arange(1,21)\\nhigh_score=0\\nnof=0           \\nscore_list_train =[]\\nscore_list_val =[]\\nfor n in numberK_list:\\n    model = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\\n    score_train = model.score(X_train, y_train)\\n    score_val = model.score(X_val, y_val)\\n    score_list_train.append(score_train)\\n    score_list_val.append(score_val)\\n    \\n    if(score_val>high_score):\\n        high_score = score_val\\n        nof = numberK_list[n-1]\\nprint(\"Best number of neighbors: %d\" %nof)\\nprint(\"Mean accuracy in train with %d neighbors: %f\" % (nof, score_list_train[nof-1]))\\nprint(\"Mean accuracy in validation with %d neighbors: %f\" % (nof, high_score))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"numberK_list=np.arange(1,21)\n",
    "high_score=0\n",
    "nof=0           \n",
    "score_list_train =[]\n",
    "score_list_val =[]\n",
    "for n in numberK_list:\n",
    "    model = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_val = model.score(X_val, y_val)\n",
    "    score_list_train.append(score_train)\n",
    "    score_list_val.append(score_val)\n",
    "    \n",
    "    if(score_val>high_score):\n",
    "        high_score = score_val\n",
    "        nof = numberK_list[n-1]\n",
    "print(\"Best number of neighbors: %d\" %nof)\n",
    "print(\"Mean accuracy in train with %d neighbors: %f\" % (nof, score_list_train[nof-1]))\n",
    "print(\"Mean accuracy in validation with %d neighbors: %f\" % (nof, high_score))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fe001",
   "metadata": {},
   "source": [
    "Best number of neighbors: 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b94317e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.plot(numberK_list, score_list_train, label='Train')\\nplt.plot(numberK_list, score_list_val, label = 'Validation')\\nplt.vlines(x=nof,ymax=high_score,ymin=min(score_list_val),ls='--',colors='g')\\nplt.xticks(numberK_list)\\nplt.xlabel('k')\\nplt.ylabel('score')\\nplt.legend()\\n\\nplt.show()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.plot(numberK_list, score_list_train, label='Train')\n",
    "plt.plot(numberK_list, score_list_val, label = 'Validation')\n",
    "plt.vlines(x=nof,ymax=high_score,ymin=min(score_list_val),ls='--',colors='g')\n",
    "plt.xticks(numberK_list)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('score')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c26aa9",
   "metadata": {},
   "source": [
    "With this last 2 cells we conclude that the best number of neighbors is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da3ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opt_method = [\"auto\", \"ball_tree\", \"kd_tree\"]\\nhigh_score=0\\nnof=0           \\nscore_list_train =[]\\nscore_list_val =[]\\nfor method in opt_method:\\n    \\n    model = KNeighborsClassifier(n_neighbors = 6, algorithm = method ).fit(X_train, y_train)\\n    score_train = model.score(X_train, y_train)\\n    score_val = model.score(X_val, y_val)\\n    score_list_train.append(score_train)\\n    score_list_val.append(score_val)\\nfor n in range(len(score_list_val)):   \\n    if score_list_val[n-1]> high_score:\\n        high_score = score_list_val[n-1]\\n        nof = opt_method[n-1]\\n        \\nprint(f\"Best method: {nof}\")\\nprint(f\"Mean accuracy in train with algorithm =  {nof}: {score_list_train[n-1]}\")\\nprint(f\"Mean accuracy in validation with algorithm = {nof}: {high_score}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"opt_method = [\"auto\", \"ball_tree\", \"kd_tree\"]\n",
    "high_score=0\n",
    "nof=0           \n",
    "score_list_train =[]\n",
    "score_list_val =[]\n",
    "for method in opt_method:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors = 6, algorithm = method ).fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_val = model.score(X_val, y_val)\n",
    "    score_list_train.append(score_train)\n",
    "    score_list_val.append(score_val)\n",
    "for n in range(len(score_list_val)):   \n",
    "    if score_list_val[n-1]> high_score:\n",
    "        high_score = score_list_val[n-1]\n",
    "        nof = opt_method[n-1]\n",
    "        \n",
    "print(f\"Best method: {nof}\")\n",
    "print(f\"Mean accuracy in train with algorithm =  {nof}: {score_list_train[n-1]}\")\n",
    "print(f\"Mean accuracy in validation with algorithm = {nof}: {high_score}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a56249",
   "metadata": {},
   "source": [
    "With this last cell we conclude that the best method is kd_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbd0e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opt_dist = [\"euclidean\", \"manhattan\", \"minkowski\"]\\nhigh_score=0\\nnof=0           \\nscore_list_train =[]\\nscore_list_val =[]\\nfor dist in opt_dist:\\n    \\n    model = KNeighborsClassifier(n_neighbors = 6, algorithm = \"kd_tree\", metric = dist).fit(X_train, y_train)\\n    score_train = model.score(X_train, y_train)\\n    score_val = model.score(X_val, y_val)\\n    score_list_train.append(score_train)\\n    score_list_val.append(score_val)\\nfor n in range(len(score_list_val)):   \\n    if score_list_val[n-1]> high_score:\\n        high_score = score_list_val[n-1]\\n        nof = opt_dist[n-1]\\n        \\nprint(f\"Best method: {nof}\")\\nprint(f\"Mean accuracy in train with algorithm =  {nof}: {score_list_train[n-1]}\")\\nprint(f\"Mean accuracy in validation with algorithm = {nof}: {high_score}\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"opt_dist = [\"euclidean\", \"manhattan\", \"minkowski\"]\n",
    "high_score=0\n",
    "nof=0           \n",
    "score_list_train =[]\n",
    "score_list_val =[]\n",
    "for dist in opt_dist:\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors = 6, algorithm = \"kd_tree\", metric = dist).fit(X_train, y_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "    score_val = model.score(X_val, y_val)\n",
    "    score_list_train.append(score_train)\n",
    "    score_list_val.append(score_val)\n",
    "for n in range(len(score_list_val)):   \n",
    "    if score_list_val[n-1]> high_score:\n",
    "        high_score = score_list_val[n-1]\n",
    "        nof = opt_dist[n-1]\n",
    "        \n",
    "print(f\"Best method: {nof}\")\n",
    "print(f\"Mean accuracy in train with algorithm =  {nof}: {score_list_train[n-1]}\")\n",
    "print(f\"Mean accuracy in validation with algorithm = {nof}: {high_score}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af220e37",
   "metadata": {},
   "source": [
    "With this last cell we conclude that the mest metric is minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ad06813",
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors = 6, algorithm = \"kd_tree\", metric = \"minkowski\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c1d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7911837251929126"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, knc.predict(X_val), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b9dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.90       323\n",
      "         1.0       0.87      0.70      0.78       176\n",
      "\n",
      "    accuracy                           0.86       499\n",
      "   macro avg       0.86      0.82      0.84       499\n",
      "weighted avg       0.86      0.86      0.86       499\n",
      "\n",
      "[[305  18]\n",
      " [ 52 124]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.91      0.85       138\n",
      "         1.0       0.79      0.59      0.68        76\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.75      0.77       214\n",
      "weighted avg       0.80      0.80      0.79       214\n",
      "\n",
      "[[126  12]\n",
      " [ 31  45]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = knc.predict(X_train) , y_test = y_val, pred_test = knc.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3b494",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e558e33",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d90c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We don't have a function to study the best parameter as this functions doesn't take significant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ae5d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_nb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6566b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872445336725317"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, gaussian_nb.predict(X_val), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0783804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85       323\n",
      "         1.0       0.73      0.68      0.70       176\n",
      "\n",
      "    accuracy                           0.80       499\n",
      "   macro avg       0.78      0.77      0.78       499\n",
      "weighted avg       0.80      0.80      0.80       499\n",
      "\n",
      "[[278  45]\n",
      " [ 56 120]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.86      0.84       138\n",
      "         1.0       0.72      0.66      0.69        76\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.77      0.76      0.77       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n",
      "[[119  19]\n",
      " [ 26  50]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = gaussian_nb.predict(X_train) , y_test = y_val, pred_test = gaussian_nb.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953cb4a",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b0503d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f19baacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"parameter_space = {\\n    'max_depth': [3,4,5,6,7,8,9],\\n    'criterion': ['entropy', 'log_loss','gini'],\\n    'splitter': ['random', 'best'],\\n    'max_features': [2,4,6,8,10,None],\\n    'max_leaf_nodes': [3,6,9,12, None]\\n}\\n\\nclf = GridSearchCV(dt, parameter_space, scoring = 'neg_mean_squared_error')\\nclf.fit(X_train,y_train)\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"parameter_space = {\n",
    "    'max_depth': [3,4,5,6,7,8,9],\n",
    "    'criterion': ['entropy', 'log_loss','gini'],\n",
    "    'splitter': ['random', 'best'],\n",
    "    'max_features': [2,4,6,8,10,None],\n",
    "    'max_leaf_nodes': [3,6,9,12, None]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(dt, parameter_space, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train,y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b0d31a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Best parameter set\\nprint(\\'------------------------------------------------------------------------------------------------------------------------\\')\\nprint(\\'Best parameters found:\\n\\', clf.best_params_)\\nprint(\\'------------------------------------------------------------------------------------------------------------------------\\')\\n\\n# All results\\nmeans = clf.cv_results_[\\'mean_test_score\\']\\nstds = clf.cv_results_[\\'std_test_score\\']\\nfor mean, std, params in zip(means, stds, clf.cv_results_[\\'params\\']):\\n    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std , params))\\n    \\n# Best results\\nprint(\"BEST RESULTS: %0.5f (+/-%0.05f) for %r\" % (clf.best_score_,                                     clf.cv_results_[\\'std_test_score\\'][clf.best_index_], clf.best_params_))'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Best parameter set\n",
    "print('------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "print('------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std , params))\n",
    "    \n",
    "# Best results\n",
    "print(\"BEST RESULTS: %0.5f (+/-%0.05f) for %r\" % (clf.best_score_, \\\n",
    "                                    clf.cv_results_['std_test_score'][clf.best_index_], clf.best_params_))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb8281",
   "metadata": {},
   "source": [
    "This tells us that the best results using the Decision Tree Classifier are obtained when the parameters are:\n",
    "`criterion = 'gini'`, `max_depth = 4`, `max_features: 8`, `max_leaf_nodes: 10`, `splitter: 'random'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3187850",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(criterion = 'gini', max_depth = 4, max_features = 8, max_leaf_nodes = 10, splitter = 'random', random_state = 8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2474a1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7967003321759747"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, dt_best.predict(X_val), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26e47cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.88       323\n",
      "         1.0       0.80      0.75      0.77       176\n",
      "\n",
      "    accuracy                           0.85       499\n",
      "   macro avg       0.83      0.82      0.83       499\n",
      "weighted avg       0.84      0.85      0.84       499\n",
      "\n",
      "[[290  33]\n",
      " [ 44 132]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.87      0.85       138\n",
      "         1.0       0.74      0.67      0.70        76\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.78      0.77      0.78       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "[[120  18]\n",
      " [ 25  51]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = dt_best.predict(X_train) , y_test = y_val, pred_test = dt_best.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d61cbd",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11871671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_bagging_classifier_params(X, y, base_estimator = None):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Create a BaggingClassifier\n",
    "    bagging_clf = BaggingClassifier(estimator = base_estimator)\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {'n_estimators': [10, 50, 100, 150],\n",
    "                  'max_samples': [0.3, 0.5, 0.7, 1.0],\n",
    "                  'max_features': [0.5, 0.7, 1.0],\n",
    "                  \"bootstrap\" : [True, False],\n",
    "                  'bootstrap_features' : [True, False]}\n",
    "\n",
    "    # Use F1 score as the scoring metric for GridSearchCV\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "    # Create the RepeatedStratifiedKFold object\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "    # Create the GridSearchCV object with RepeatedStratifiedKFold\n",
    "    grid_search = GridSearchCV(bagging_clf, param_grid, scoring=f1_scorer, cv=cv)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d9e77",
   "metadata": {},
   "source": [
    "## Bagging Classifier with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dba7e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because it takes a long time running\n",
    "#find_best_bagging_classifier_params(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c378bd3",
   "metadata": {},
   "source": [
    "Best Parameters: {'bootstrap': False, 'bootstrap_features': False, 'max_features': 0.5, 'max_samples': 0.1, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "543cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdt = BaggingClassifier(bootstrap = False, bootstrap_features = False, max_features = 0.5, max_samples = 0.1, n_estimators = 100, random_state = 8)\n",
    "bcdt = bcdt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73e27da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8007532730314232"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, bcdt.predict(X_val), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a10aef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.97      0.91       323\n",
      "         1.0       0.92      0.69      0.79       176\n",
      "\n",
      "    accuracy                           0.87       499\n",
      "   macro avg       0.88      0.83      0.85       499\n",
      "weighted avg       0.88      0.87      0.86       499\n",
      "\n",
      "[[312  11]\n",
      " [ 54 122]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.99      0.87       138\n",
      "         1.0       0.95      0.51      0.67        76\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.87      0.75      0.77       214\n",
      "weighted avg       0.84      0.82      0.80       214\n",
      "\n",
      "[[136   2]\n",
      " [ 37  39]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = bcdt.predict(X_train) , y_test = y_val, pred_test = bcdt.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bed29",
   "metadata": {},
   "source": [
    "## Bagging Classifier with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bd142a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because it takes a long time running\n",
    "#find_best_bagging_classifier_params(X, y, base_estimator = KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a71a4",
   "metadata": {},
   "source": [
    "Best Parameters: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 0.5, 'max_samples': 0.2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8e50a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcknc = BaggingClassifier(bootstrap = True, bootstrap_features = False, max_features = 0.5, max_samples = 0.2, n_estimators = 100, random_state = 8)\n",
    "bcknc = bcknc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "724ec1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811752928358734"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, bcknc.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc730eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.98      0.92       323\n",
      "         1.0       0.94      0.72      0.82       176\n",
      "\n",
      "    accuracy                           0.89       499\n",
      "   macro avg       0.90      0.85      0.87       499\n",
      "weighted avg       0.89      0.89      0.88       499\n",
      "\n",
      "[[315   8]\n",
      " [ 49 127]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.96      0.87       138\n",
      "         1.0       0.88      0.58      0.70        76\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.84      0.77      0.79       214\n",
      "weighted avg       0.83      0.82      0.81       214\n",
      "\n",
      "[[132   6]\n",
      " [ 32  44]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = bcknc.predict(X_train) , y_test = y_val, pred_test = bcknc.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060f5b1",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c740d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_RF_Classifier(X, y):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Create a BaggingClassifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid_rf = {\n",
    "                    'n_estimators': [10, 50, 100],\n",
    "                    'max_depth': [None, 10, 20, 30],\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 4],\n",
    "                    'max_features': [None, 'sqrt', 'log2']}\n",
    "    \n",
    "    # Use F1 score as the scoring metric for GridSearchCV\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "    # Create the RepeatedStratifiedKFold object\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=15)\n",
    "\n",
    "    # Create the GridSearchCV object with RepeatedStratifiedKFold\n",
    "    grid_search = GridSearchCV(rf_classifier, param_grid_rf, scoring=f1_scorer, cv=cv)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa01e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because this cell takes a long time running\n",
    "#find_best_RF_Classifier(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72a7b9",
   "metadata": {},
   "source": [
    "Best Parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "102987e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth = None, max_features = None, min_samples_leaf = 1, min_samples_split = 6, n_estimators = 100, random_state = 8)\n",
    "rfc = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "504f062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115693633731336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, rfc.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9002764f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       323\n",
      "         1.0       0.96      0.89      0.92       176\n",
      "\n",
      "    accuracy                           0.95       499\n",
      "   macro avg       0.95      0.93      0.94       499\n",
      "weighted avg       0.95      0.95      0.95       499\n",
      "\n",
      "[[317   6]\n",
      " [ 20 156]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.92      0.87       138\n",
      "         1.0       0.81      0.63      0.71        76\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.82      0.78      0.79       214\n",
      "weighted avg       0.82      0.82      0.81       214\n",
      "\n",
      "[[127  11]\n",
      " [ 28  48]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = rfc.predict(X_train) , y_test = y_val, pred_test = rfc.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e91e8a",
   "metadata": {},
   "source": [
    "# Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2533a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_f1score(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=15)\n",
    "    n_scores = cross_val_score(model, X, y, scoring = 'f1', cv = cv)\n",
    "    return n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d22b859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_results(models):\n",
    "    results, names = [],[]\n",
    "    for name, model in tqdm(models.items()):\n",
    "        scores = return_f1score(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.boxplot(results, labels = names, showmeans = True)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b647e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_results_bar(models):\n",
    "    results, names, mean, std = [],[],[],[]\n",
    "    for name, model in tqdm(models.items()):\n",
    "        scores = return_f1score(model, X, y)\n",
    "        results.append(scores)\n",
    "        names.append(name)\n",
    "        print('>%s %.3f (%.3f)' % (name, scores.mean(), scores.std()))\n",
    "        mean.append(scores.mean())\n",
    "        std.append(scores.std())\n",
    "    \n",
    "    #creates a dataset\n",
    "    data = pd.DataFrame({'Model' : names, 'F1_Mean': mean, 'F1_std': std})\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    sns.barplot(x = 'Model', y = 'F1_Mean', data = data, \n",
    "               color = 'skyblue')\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5011a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators =[('lr',  LogisticRegression(random_state = 8)),\n",
    "              ('kn', KNeighborsClassifier())]\n",
    "dt = DecisionTreeClassifier(max_depth=3,random_state = 8).fit(X_train,y_train)\n",
    "bg = BaggingClassifier(random_state = 8).fit(X_train,y_train)\n",
    "rf = RandomForestClassifier(random_state = 8).fit(X_train,y_train)\n",
    "lr = LogisticRegression(random_state = 8).fit(X_train,y_train)\n",
    "nb = GaussianNB().fit(X_train,y_train)\n",
    "kn = KNeighborsClassifier().fit(X_train,y_train)\n",
    "estimators_2 = [('rf', RandomForestClassifier(random_state = 8)),\n",
    "              ('dt', DecisionTreeClassifier()),\n",
    "               ('bg', BaggingClassifier())]\n",
    "estimators_3 = [('rf', RandomForestClassifier(random_state = 8)),\n",
    "              ('nb', GaussianNB())]\n",
    "estimators_4 = [('rf', RandomForestClassifier(random_state = 8)),\n",
    "              ('dt', DecisionTreeClassifier(max_depth = 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a182f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc = StackingClassifier(estimators=estimators,final_estimator=LogisticRegression()).fit(X_train,y_train)\n",
    "stc_2 = StackingClassifier(estimators=estimators_2,final_estimator=LogisticRegression()).fit(X_train,y_train)\n",
    "stc_3 = StackingClassifier(estimators=estimators_3,final_estimator=LogisticRegression()).fit(X_train,y_train)\n",
    "stc_4 = StackingClassifier(estimators=estimators_4,final_estimator=LogisticRegression()).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "667463ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return_results_bar(models={'lr':lr,'nb':nb,'kn':kn,'dt':dt,'bg':bg,'rf':rf, 'stc':stc, 'stc_2': stc_2, \"stc_3\": stc_3, \"stc_4\": stc_4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e0368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_stacking_classifier(X, y, n_splits=5, n_repeats=2):\n",
    "    \"\"\"\n",
    "    Optimize StackingClassifier parameters to maximize F1 score using RepeatedStratifiedKFold.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features\n",
    "    - y: Target variable\n",
    "    - n_splits: Number of splits for RepeatedStratifiedKFold\n",
    "    - n_repeats: Number of repeats for RepeatedStratifiedKFold\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Best hyperparameters that maximize F1 score\n",
    "    - best_f1_score: Maximum F1 score achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Create RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'stack_method': ['auto', 'predict_proba'],  # Choose the stack method based on your use case\n",
    "        'final_estimator': [LogisticRegression(), DecisionTreeClassifier(max_depth=1)],\n",
    "        'cv': [2, 5],  # Number of cross-validation folds for the stacking meta-estimator\n",
    "        # Add other hyperparameters as needed\n",
    "    }\n",
    "\n",
    "    base_estimators = [('rf', RandomForestClassifier(random_state = 8)),\n",
    "              ('dt', DecisionTreeClassifier(max_depth = 1))]\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate through hyperparameter combinations\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        f1_scores = []\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, val_index in rskf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            # Initialize StackingClassifier with current parameters\n",
    "            stacking_classifier = StackingClassifier(estimators=base_estimators, **params)\n",
    "\n",
    "            # Fit the model\n",
    "            stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on validation data\n",
    "            y_pred = stacking_classifier.predict(X_val)\n",
    "\n",
    "            # Calculate F1 score and append to list\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        # Calculate mean F1 score for the current parameter combination\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "\n",
    "        # Update best parameters if the current combination has a higher F1 score\n",
    "        if mean_f1_score > best_f1_score:\n",
    "            best_f1_score = mean_f1_score\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be06c827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Coded because this cell takes a long time running\n",
    "#optimize_stacking_classifier(X, y, n_splits=5, n_repeats=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1234e",
   "metadata": {},
   "source": [
    "Best Parameters: {\"estimators\" : estimators, 'cv': 3, 'final_estimator': LogisticRegression(), 'stack_method': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6cf9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_final = StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state = 8)), ('dt', DecisionTreeClassifier(max_depth = 1))], cv = 3, final_estimator = LogisticRegression(), stack_method = 'auto').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b172e36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975705453094053"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, stc_final.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b2f56dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99       323\n",
      "         1.0       1.00      0.95      0.97       176\n",
      "\n",
      "    accuracy                           0.98       499\n",
      "   macro avg       0.99      0.97      0.98       499\n",
      "weighted avg       0.98      0.98      0.98       499\n",
      "\n",
      "[[323   0]\n",
      " [  9 167]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.91      0.86       138\n",
      "         1.0       0.78      0.62      0.69        76\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.76      0.77       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n",
      "[[125  13]\n",
      " [ 29  47]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = stc_final.predict(X_train) , y_test = y_val, pred_test = stc_final.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5950ad8",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c887b",
   "metadata": {},
   "source": [
    "This will be the choice of algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60d06df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_adaboost_classifier(X, y, n_splits=5, n_repeats=2):\n",
    "    \"\"\"\n",
    "    Optimize AdaBoostClassifier parameters to maximize F1 score using RepeatedStratifiedKFold.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features\n",
    "    - y: Target variable\n",
    "    - n_splits: Number of splits for RepeatedStratifiedKFold\n",
    "    - n_repeats: Number of repeats for RepeatedStratifiedKFold\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Best hyperparameters that maximize F1 score\n",
    "    - best_f1_score: Maximum F1 score achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Create RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=15)\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.5, 1.0],\n",
    "        'base_estimator': [None, DecisionTreeClassifier(max_depth=1), LogisticRegression()],\n",
    "        'algorithm': ['SAMME', 'SAMME.R']\n",
    "    }\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate through hyperparameter combinations\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        f1_scores = []\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, val_index in rskf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            # Initialize AdaBoostClassifier with current parameters\n",
    "            adaboost_classifier = AdaBoostClassifier(**params)\n",
    "\n",
    "            # Fit the model\n",
    "            adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on validation data\n",
    "            y_pred = adaboost_classifier.predict(X_val)\n",
    "\n",
    "            # Calculate F1 score and append to list\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        # Calculate mean F1 score for the current parameter combination\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "\n",
    "        # Update best parameters if the current combination has a higher F1 score\n",
    "        if mean_f1_score > best_f1_score:\n",
    "            best_f1_score = mean_f1_score\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d199da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because this cell takes a long time running\n",
    "#optimize_adaboost_classifier(X, y, n_splits=5, n_repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6cd6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_1 = AdaBoostClassifier(algorithm = 'SAMME', base_estimator = None, learning_rate = 0.5, n_estimators = 150).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa976146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       323\n",
      "         1.0       0.79      0.75      0.77       176\n",
      "\n",
      "    accuracy                           0.84       499\n",
      "   macro avg       0.83      0.82      0.82       499\n",
      "weighted avg       0.84      0.84      0.84       499\n",
      "\n",
      "[[288  35]\n",
      " [ 44 132]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.83       138\n",
      "         1.0       0.69      0.64      0.67        76\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.75      0.74      0.75       214\n",
      "weighted avg       0.77      0.77      0.77       214\n",
      "\n",
      "[[116  22]\n",
      " [ 27  49]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = abc_1.predict(X_train) , y_test = y_val, pred_test = abc_1.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1de1964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_2 = AdaBoostClassifier(algorithm = 'SAMME', base_estimator = LogisticRegression(), learning_rate = 0.5, n_estimators = 150).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e74dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86       323\n",
      "         1.0       0.75      0.73      0.74       176\n",
      "\n",
      "    accuracy                           0.82       499\n",
      "   macro avg       0.80      0.80      0.80       499\n",
      "weighted avg       0.82      0.82      0.82       499\n",
      "\n",
      "[[281  42]\n",
      " [ 48 128]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.86      0.83       138\n",
      "         1.0       0.71      0.63      0.67        76\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.74      0.75       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n",
      "[[118  20]\n",
      " [ 28  48]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = abc_2.predict(X_train) , y_test = y_val, pred_test = abc_2.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e5dd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_3 = AdaBoostClassifier(algorithm = 'SAMME', base_estimator = LogisticRegression(), learning_rate = 0.3, n_estimators = 100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fe8d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.84       323\n",
      "         1.0       0.70      0.74      0.72       176\n",
      "\n",
      "    accuracy                           0.80       499\n",
      "   macro avg       0.78      0.79      0.78       499\n",
      "weighted avg       0.80      0.80      0.80       499\n",
      "\n",
      "[[267  56]\n",
      " [ 45 131]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.81      0.82       138\n",
      "         1.0       0.68      0.71      0.69        76\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "[[112  26]\n",
      " [ 22  54]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = abc_3.predict(X_train) , y_test = y_val, pred_test = abc_3.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb42804",
   "metadata": {},
   "source": [
    "Best Parameters: {'algorithm': 'SAMME', 'base_estimator': LogisticRegression(), 'learning_rate': 0.1, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f32cd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_best = AdaBoostClassifier(algorithm = 'SAMME', base_estimator = LogisticRegression(), learning_rate = 0.1, n_estimators = 100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad3870c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7949772445986377"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, abc_best.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c78e0c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.85      0.85       323\n",
      "         1.0       0.73      0.75      0.74       176\n",
      "\n",
      "    accuracy                           0.81       499\n",
      "   macro avg       0.80      0.80      0.80       499\n",
      "weighted avg       0.81      0.81      0.81       499\n",
      "\n",
      "[[274  49]\n",
      " [ 44 132]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.83      0.84       138\n",
      "         1.0       0.71      0.72      0.71        76\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.78      0.78       214\n",
      "weighted avg       0.80      0.79      0.79       214\n",
      "\n",
      "[[115  23]\n",
      " [ 21  55]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = abc_best.predict(X_train) , y_test = y_val, pred_test = abc_best.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbc1ec",
   "metadata": {},
   "source": [
    "# GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "218e4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_gradient_boosting_classifier(X, y, n_splits=5, n_repeats=2):\n",
    "    \"\"\"\n",
    "    Optimize GradientBoostingClassifier parameters to maximize F1 score using RepeatedStratifiedKFold.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features\n",
    "    - y: Target variable\n",
    "    - n_splits: Number of splits for RepeatedStratifiedKFold\n",
    "    - n_repeats: Number of repeats for RepeatedStratifiedKFold\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Best hyperparameters that maximize F1 score\n",
    "    - best_f1_score: Maximum F1 score achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Create RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "    }\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate through hyperparameter combinations\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        f1_scores = []\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, val_index in rskf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            # Initialize GradientBoostingClassifier with current parameters\n",
    "            gradient_boosting_classifier = GradientBoostingClassifier(**params)\n",
    "\n",
    "            # Fit the model\n",
    "            gradient_boosting_classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on validation data\n",
    "            y_pred = gradient_boosting_classifier.predict(X_val)\n",
    "\n",
    "            # Calculate F1 score and append to list\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        # Calculate mean F1 score for the current parameter combination\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "\n",
    "        # Update best parameters if the current combination has a higher F1 score\n",
    "        if mean_f1_score > best_f1_score:\n",
    "            best_f1_score = mean_f1_score\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61c89d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because this cell takes a long time running\n",
    "#optimize_gradient_boosting_classifier(X, y, n_splits=5, n_repeats=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4bfc5",
   "metadata": {},
   "source": [
    "Best Parameters: {'learning_rate': 0.2, 'max_depth': 6, 'max_features': None, 'n_estimators': 100, 'subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "badf74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate = 0.2, max_depth = 6, max_features = None, n_estimators = 100, subsample = 0.7, random_state = 8)\n",
    "gbc = gbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "419e5e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054072833216956"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, gbc.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e21e1661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       323\n",
      "         1.0       1.00      1.00      1.00       176\n",
      "\n",
      "    accuracy                           1.00       499\n",
      "   macro avg       1.00      1.00      1.00       499\n",
      "weighted avg       1.00      1.00      1.00       499\n",
      "\n",
      "[[323   0]\n",
      " [  0 176]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.88      0.86       138\n",
      "         1.0       0.76      0.67      0.71        76\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.78      0.78       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n",
      "[[122  16]\n",
      " [ 25  51]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = gbc.predict(X_train) , y_test = y_val, pred_test = gbc.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095424f0",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6917423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp_classifier(X, y, n_splits=5, n_repeats=2):\n",
    "    \"\"\"\n",
    "    Optimize MLPClassifier parameters to maximize F1 score using RepeatedStratifiedKFold.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Features\n",
    "    - y: Target variable\n",
    "    - n_splits: Number of splits for RepeatedStratifiedKFold\n",
    "    - n_repeats: Number of repeats for RepeatedStratifiedKFold\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Best hyperparameters that maximize F1 score\n",
    "    - best_f1_score: Maximum F1 score achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Create RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'activation': ['relu', 'logistic', 'tanh'],\n",
    "        'solver': ['adam', 'lbfgs'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "    }\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate through hyperparameter combinations\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        f1_scores = []\n",
    "\n",
    "        # Perform cross-validation\n",
    "        for train_index, val_index in rskf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            # Initialize MLPClassifier with current parameters\n",
    "            mlp_classifier = MLPClassifier(**params)\n",
    "\n",
    "            # Fit the model\n",
    "            mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on validation data\n",
    "            y_pred = mlp_classifier.predict(X_val)\n",
    "\n",
    "            # Calculate F1 score and append to list\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        # Calculate mean F1 score for the current parameter combination\n",
    "        mean_f1_score = np.mean(f1_scores)\n",
    "\n",
    "        # Update best parameters if the current combination has a higher F1 score\n",
    "        if mean_f1_score > best_f1_score:\n",
    "            best_f1_score = mean_f1_score\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa283c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coded because this cell takes a long time running\n",
    "#optimize_mlp_classifier(X, y, n_splits=5, n_repeats=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa81a5",
   "metadata": {},
   "source": [
    "Best Parameters: {activation: 'relu', alpha: 0.3, hidden_layer_sizes: (50, 75), solver: 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f10b428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation = 'relu', alpha = 0.3, hidden_layer_sizes = (50, 75), solver = 'adam', random_state = 8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bd34c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998282028388328"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, mlp.predict(X_val), average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81ad8514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "                                                     TRAIN                                                 \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.93      0.90       323\n",
      "         1.0       0.85      0.74      0.79       176\n",
      "\n",
      "    accuracy                           0.86       499\n",
      "   macro avg       0.86      0.83      0.84       499\n",
      "weighted avg       0.86      0.86      0.86       499\n",
      "\n",
      "[[300  23]\n",
      " [ 46 130]]\n",
      "_____________________________________\n",
      "                                                     TEST                                                  \n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.93      0.86       138\n",
      "         1.0       0.82      0.59      0.69        76\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.76      0.77       214\n",
      "weighted avg       0.81      0.81      0.80       214\n",
      "\n",
      "[[128  10]\n",
      " [ 31  45]]\n"
     ]
    }
   ],
   "source": [
    "metrics(y_train = y_train, pred_train = mlp.predict(X_train) , y_test = y_val, pred_test = mlp.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7de82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
